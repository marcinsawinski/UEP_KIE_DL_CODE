{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 3: Tensorflow TensorBoard\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/marcinsawinski/UEP_KIE_DL_CODE/blob/main/dl03_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a deep MLP on the Fashion MNIST dataset.\n",
    "- Define tensorflow model with 2 hidden layers (300,100), fit it and score\n",
    "- Try searching for the optimal learning rate by growing the learning rate exponentially, plotting the loss, and finding the point where the loss shoots up. \n",
    "- Try adding all extra features â€” save checkpoints, use early stopping, and plot learning curves using TensorBoard.\n",
    "- Experiment with 3-layer Neural Networks (NN-3), a 6-layer (NN-6) and a 12-layer Neural Network (NN-12)\n",
    "- Experiment with activation functions, initialisations and optimizers\n",
    "- Add batch normalization and drop out\n",
    "- Analyse output in Tensorboard\n",
    "\n",
    "Check https://keras.io/api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class names are not included with the dataset, so we define them here\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset, split it into training, validation and test sets\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the pixel intensities to the [0, 1] range\n",
    "X_train, X_valid, X_test = X_train / 255., X_valid / 255., X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 28, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape of the training set\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAOI0lEQVR4nO3cv2/V9dvH8ev096+kFFJ+CRK/6MCAMQaIMGo0YuLA7urErIkO/gXuLkZd0WicjIGEQYkGf0TioAaNVENKsWCAtpS2tOfertz3/f0m7fVOWojfx2Pm5ed4esqTs1ydbrfbDQCIiJ4H/QIAeHiIAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKAKS+B/0CYD3dbre86XQ6m/BK/t3c3Fx5c+HChaZnnTx5smlX1fJ+r66uljd9ff+8v35a3rtWm/UZ900BgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgDpn3eRin+ctbW18qa3t7e8+e2338qbd999t7wZHh4ubyIiRkdHy5uhoaHy5tixY+XNVh63azk61/IZannOVr4PLUcIN/J74ZsCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSg3g89Dbr8Nf/d/78+fLm3Llz5c3+/fvLm4iIpaWl8ubu3bvlzdmzZ8ubV199tbzZtWtXeRMR0el0ypuWz0OL+fn5pl1PT/3f5yMjI03PWo9vCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASA7i8dAbGBjYkud8++235c3U1FR5s7a2Vt607l544YXy5ocffihvXn/99fLmyJEj5U1ExOHDh8ubQ4cOlTfffPNNedPyGYqIOHHiRHlz/Pjx8mZ8fHzdP+ObAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAUqfb7XYf9Ivgv0PrR63T6ZQ3586dK29ajrrdunWrvOnv7y9vIiJ6erbm33BHjx4tbx5//PHypvXQYcvnaGZmprzp66vfCz127Fh5ExHx0UcflTenT58ub5599tl1/4xvCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQHIllebrpVul5UrqM888U95MTU2VNy1a3+/e3t7yZnBwsOlZVUNDQ+VNy881IuLpp58ub5544onypuX9/vzzz8ubiIjff/+9vJmenm561np8UwAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQOp70C+AB6/1MNnDbGJiory5du1aeTM8PFzeLC0tlTcRESsrK+XN/Px8edNy3G5xcbG8af3cXbhwobz56quvypuWw4XXr18vbyIiXnzxxabdZvBNAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIAyUE8/pHu3r1b3qyurpY3a2tr5U3LEb2IiN27d5c3O3bsKG+mpqbKm56e+r8vWw7ORbT9nFoO9rX8P/X29pY3ERFXr15t2m0G3xQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJAcxKPpMFnLIbjWY2Hz8/PlzfT0dHkzODhY3gwMDJQ3y8vL5U1E2+sbHR0tb27fvl3etBzeazlaGNH2/o2NjZU3d+7cKW8OHz5c3kRELCwslDffffddeXPkyJF1/4xvCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQHIlleh0OuXN6upqedN6JfXMmTPlzbVr18qbycnJ8mZxcbG8aX0fWi5p/vnnn+VNf39/ebO0tFTe9PW1/fWzsrJS3rT8nG7cuFHenD59uryJiLh06VJ5c//+/aZnrcc3BQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoApE632+0+6BfBg9VyWKv1mFmLixcvljcvvfRSeTM8PFzebOVhwPn5+fJmaGiovNm+fXt50/IZajlsF9F2GHBiYqLpWVUt73dExGuvvVbevPLKK03PWo9vCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASFt31WyDWu/ztRwmW1tbK29aXl9/f39509Ozdb3eyuN2LU6ePFnejI2NlTctB/GWl5fLm1aTk5PlTcuhunv37pU3AwMD5U2rls9ry+9Ty98pP/74Y3kTETE+Pt602wy+KQCQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIG3qJbSWg1K9vb1Nz3rYj7o9zL744ovy5uOPPy5vLly4UN5ERIyMjJQ3O3bsKG+WlpbKm06nU960flZb3oeW38GW96HliF7LexcRMTo62rSrajl22PraPvnkk/Lm5ZdfbnrWenxTACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBA6nS73e6DfhEPyt9//13eTE9PlzeXL1/ekudEtB3Wanl9g4OD5c3a2lp5ExExMDBQ3iwuLpY3e/fuLW9ajqatrKyUNxERN27cKG9afk53794tb06cOFHezM3NlTcREV9++WV509NT//fv+Ph4edPyeYiI2L17d3nz888/Nz1rPb4pAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIAaVOvpH799dflzVtvvdX0rNnZ2fLm1q1b5U3LtcWW66Dbtm0rbyIient7y5uWq5gt1zdbP2rDw8PlzaFDh8qbM2fOlDdHjx4tb+7cuVPeRLR9XqemppqeVfXYY4+VN/Pz803PGhsbK29GR0fLm5bfi4WFhfImIuL27dvlTcsl4I3wTQGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAGnDB/FWV1fL//Hjx4+XN9PT0+VNRERfX19503LcruWwVov79+837VqOx22VlqNfERE3b94sbz744IPy5uzZs+XNO++8U97s2bOnvImIGBoaKm9aDtUdPHiwvPn111/Lm5afa0REf39/edPy+9RyuHBlZaW8iWg7ZPnHH380PWs9vikAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACBt+CDee++9V/6Pv/HGG+XNv/71r/ImImJhYaG8mZubK2+WlpbKmxatB/Fajs7t27evvHnkkUfKm9nZ2fImImJtba28mZmZKW8+/fTT8ubevXvlzZUrV8qbiLbP+Pfff78lm5aDmYODg+VNRNvnYXl5uelZVRv86/TftLy+ixcvljf79+9f98/4pgBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgNS30T+4c+fO8n+85dBay5G6iLbjWo8++mh50/L6VlZWyps7d+6UNxER27dvL28OHDhQ3rS8D0NDQ+VN6663t7e8OXXqVHlz+PDh8mZqaqq8iYi4efNmedPye7Ft27bypr+/v7xp+RlFRAwMDJQ3LQfnenrq/2ZuPYjXsrt8+XJ54yAeACWiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQNnwQr+W4XctBqY0cbPpPFhYWypvZ2dnypuVY2OTk5JZsIiLu379f3iwtLW3Jc+7du1feRETMz8+XN6urq+XNjh07ypuffvqpvBkbGytvItoOOE5MTJQ3LT+nls9rX9+G//r5P1qO77U8a3FxsbyZmZkpbyIixsfHy5tLly6VN88999y6f8Y3BQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIG34dOBTTz1V/o+fOnWqvHn//ffLm4iIvXv3ljcHDx4sb4aGhsqbliufy8vL5U1E22XHlZWV8qblSmrLe9f6rE6nU96MjIyUN3v27ClvWq4HR0T09vaWNy3vXcsl4Lm5ufJmcHCwvIloe30tm4GBgfKm5YJrRMSVK1fKm127djU9az2+KQCQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIHW63W73Qb+I/+2zzz5r2r399tvlzV9//VXeTE5Oljctx7haj6atra2VN0tLS+XN6upqedNynC0iouUj2nIQr+X1tRwubD122PL6turXu+U5O3fu3IRX8p+1HH1s+R2cmZkpbyIinnzyyfLmww8/bHrWenxTACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBA2vBBvJZDa61H3bbK+fPny5s333yzvLl+/Xp5c/v27fImou0wWctxu5YDY319feVNxNYdW2s5ordv377ypvX3YmxsrLxp+dlulYGBgabdyMhIedPy99fzzz9f3hw6dKi8iYg4ceJE024zPNx/awOwpUQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACBt+CAeW+uXX35p2s3OzpY3ExMT5c3Vq1fLmwMHDpQ3EW2H0w4ePNj0LPhv55sCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQXEkFIPmmAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQ/ge0qfPOeiUN1wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the first image in the training set\n",
    "plt.imshow(X_train[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a callback that will print the validation/train ratio at the end of each epoch\n",
    "class PrintValTrainRatioCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        ratio = logs[\"val_loss\"] / logs[\"loss\"]\n",
    "        print(f\"Epoch={epoch}, val/train={ratio:.2f}\")\n",
    "\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_checkpoints\",\n",
    "                                                   save_weights_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:34:17.072063: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2023-03-21 11:34:17.072073: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "2023-03-21 11:34:17.072130: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "   1/1719 [..............................] - ETA: 10:00 - loss: 2.6443 - accuracy: 0.0938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:34:17.505589: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 125/1719 [=>............................] - ETA: 13s - loss: 1.0189 - accuracy: 0.6375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:34:18.531991: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2023-03-21 11:34:18.532006: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 211/1719 [==>...........................] - ETA: 16s - loss: 0.8757 - accuracy: 0.6832"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:34:19.731023: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
      "2023-03-21 11:34:19.750857: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2023-03-21 11:34:19.761951: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/fashion_mnist_lr0.01_do0.2_p1020230321-113417/plugins/profile/2023_03_21_11_34_19\n",
      "\n",
      "2023-03-21 11:34:19.775044: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/fashion_mnist_lr0.01_do0.2_p1020230321-113417/plugins/profile/2023_03_21_11_34_19/MB16MS.local.trace.json.gz\n",
      "2023-03-21 11:34:19.799364: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/fashion_mnist_lr0.01_do0.2_p1020230321-113417/plugins/profile/2023_03_21_11_34_19\n",
      "\n",
      "2023-03-21 11:34:19.802546: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/fashion_mnist_lr0.01_do0.2_p1020230321-113417/plugins/profile/2023_03_21_11_34_19/MB16MS.local.memory_profile.json.gz\n",
      "2023-03-21 11:34:19.804596: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/fashion_mnist_lr0.01_do0.2_p1020230321-113417/plugins/profile/2023_03_21_11_34_19\n",
      "Dumped tool data for xplane.pb to logs/fashion_mnist_lr0.01_do0.2_p1020230321-113417/plugins/profile/2023_03_21_11_34_19/MB16MS.local.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/fashion_mnist_lr0.01_do0.2_p1020230321-113417/plugins/profile/2023_03_21_11_34_19/MB16MS.local.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/fashion_mnist_lr0.01_do0.2_p1020230321-113417/plugins/profile/2023_03_21_11_34_19/MB16MS.local.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/fashion_mnist_lr0.01_do0.2_p1020230321-113417/plugins/profile/2023_03_21_11_34_19/MB16MS.local.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/fashion_mnist_lr0.01_do0.2_p1020230321-113417/plugins/profile/2023_03_21_11_34_19/MB16MS.local.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - ETA: 0s - loss: 0.5814 - accuracy: 0.7917"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:34:31.145048: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 15s 8ms/step - loss: 0.5814 - accuracy: 0.7917 - val_loss: 0.4379 - val_accuracy: 0.8416\n",
      "Epoch 2/40\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 0.4659 - accuracy: 0.8323 - val_loss: 0.4403 - val_accuracy: 0.8332\n",
      "Epoch 3/40\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.4433 - accuracy: 0.8415 - val_loss: 0.4262 - val_accuracy: 0.8488\n",
      "Epoch 4/40\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.4299 - accuracy: 0.8467 - val_loss: 0.4111 - val_accuracy: 0.8490\n",
      "Epoch 5/40\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.4238 - accuracy: 0.8489 - val_loss: 0.3998 - val_accuracy: 0.8586\n",
      "Epoch 6/40\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 0.4218 - accuracy: 0.8522 - val_loss: 0.4078 - val_accuracy: 0.8558\n",
      "Epoch 7/40\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.4071 - accuracy: 0.8555 - val_loss: 0.4166 - val_accuracy: 0.8560\n",
      "Epoch 8/40\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.4105 - accuracy: 0.8570 - val_loss: 0.4287 - val_accuracy: 0.8532\n",
      "Epoch 9/40\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.3954 - accuracy: 0.8588 - val_loss: 0.4102 - val_accuracy: 0.8574\n",
      "Epoch 10/40\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.3973 - accuracy: 0.8611 - val_loss: 0.4833 - val_accuracy: 0.8434\n",
      "Epoch 11/40\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.3885 - accuracy: 0.8614 - val_loss: 0.4159 - val_accuracy: 0.8666\n",
      "Epoch 12/40\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.3877 - accuracy: 0.8642 - val_loss: 0.4317 - val_accuracy: 0.8644\n",
      "Epoch 13/40\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.3846 - accuracy: 0.8635 - val_loss: 0.4381 - val_accuracy: 0.8540\n",
      "Epoch 14/40\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.3903 - accuracy: 0.8637 - val_loss: 0.4528 - val_accuracy: 0.8528\n",
      "Epoch 15/40\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.3855 - accuracy: 0.8654 - val_loss: 0.4336 - val_accuracy: 0.8494\n"
     ]
    }
   ],
   "source": [
    "# define the hyperparameters\n",
    "learning_rate = 0.01\n",
    "dropout_rate = 0.2\n",
    "patience = 10\n",
    "\n",
    "\n",
    "# define the model with different numbers of hidden layers and 10 output neurons and softmax activation\n",
    "# experiment with different dropout rates and learning rates\n",
    "model_base = tf.keras.Sequential(\n",
    "    [\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dropout(dropout_rate, name=\"dropout1\"),\n",
    "    tf.keras.layers.Dense(300, activation=\"relu\", name=\"hidden1\"),\n",
    "    # tf.keras.layers.Dropout(dropout_rate, name=\"dropout2\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\", name=\"hidden2\"),\n",
    "    # tf.keras.layers.Dropout(dropout_rate, name=\"dropout3\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\", name=\"output\"),\n",
    "    ]\n",
    "    )\n",
    "\n",
    "# define the tensorboard callback\n",
    "ts = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = os.path.join(\"logs\", f\"fashion_mnist_lr{learning_rate}_do{dropout_rate}_p{patience}{ts}\")\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(logdir,\n",
    "                                                profile_batch=(100, 200))\n",
    "# define the early stopping callback\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=patience,\n",
    "                                                     restore_best_weights=True)\n",
    "# make a copy of the model so you can use it multiple times\n",
    "model = tf.keras.models.clone_model(model_base)\n",
    "\n",
    "# define the optimizer \n",
    "opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=opt,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# train the model\n",
    "history = model.fit(X_train, y_train, epochs=40,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[early_stopping_cb,tensorboard_cb])\n",
    "# you can plot history to see the training history when not using tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the hyperparameters and retrain the model while checking the tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tensorboard extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-359b2e9a2f5ca91e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-359b2e9a2f5ca91e\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hml3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac2598a53cd48ed973662853cbed9ce85601c819c2e7e5e54efa32ca245c1cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/marcinsawinski/UEP_KIE_DL_CODE/blob/main/dl05_cnn_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5\n",
    " - Build your own CNN from scratch and try to achieve the highest possible accuracy on MNIST.\n",
    " - Use Pretrained Models from Keras, e.g.\n",
    " ```python\n",
    " model = tf.keras.applications.ResNet50(weights=\"imagenet\")\n",
    " ```\n",
    " - Transfer stype - follow https://www.tensorflow.org/tutorials/generative/style_transfer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os, datetime \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class names are not included with the dataset, so we define them here\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]\n",
    "# scale the pixel intensities to the [0, 1] range\n",
    "X_train, X_valid, X_test = X_train / 255., X_valid / 255., X_test / 255.\n",
    "# check the shape of the training set\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the hyperparameters\n",
    "learning_rate = 0.01\n",
    "dropout_rate = 0.2\n",
    "patience = 10\n",
    "\n",
    "\n",
    "# define the model with different numbers of hidden layers and 10 output neurons and softmax activation\n",
    "# experiment with different dropout rates and learning rates\n",
    "model_base = tf.keras.Sequential(\n",
    "    [\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dropout(dropout_rate, name=\"dropout1\"),\n",
    "    tf.keras.layers.Dense(300, activation=\"relu\", name=\"hidden1\"),\n",
    "    # tf.keras.layers.Dropout(dropout_rate, name=\"dropout2\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\", name=\"hidden2\"),\n",
    "    # tf.keras.layers.Dropout(dropout_rate, name=\"dropout3\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\", name=\"output\"),\n",
    "    ]\n",
    "    )\n",
    "\n",
    "# define the tensorboard callback\n",
    "ts = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = os.path.join(\"logs\", f\"fashion_mnist_lr{learning_rate}_do{dropout_rate}_p{patience}{ts}\")\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(logdir,\n",
    "                                                profile_batch=(100, 200))\n",
    "# define the early stopping callback\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=patience,\n",
    "                                                     restore_best_weights=True)\n",
    "# make a copy of the model so you can use it multiple times\n",
    "model = tf.keras.models.clone_model(model_base)\n",
    "\n",
    "# define the optimizer \n",
    "opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=opt,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# train the model\n",
    "history = model.fit(X_train, y_train, epochs=40,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[early_stopping_cb,tensorboard_cb])\n",
    "# you can plot history to see the training history when not using tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the hyperparameters\n",
    "learning_rate = 0.01\n",
    "dropout_rate = 0.2\n",
    "patience = 4\n",
    "\n",
    "\n",
    "# define the model with different numbers of hidden layers and 10 output neurons and softmax activation\n",
    "# experiment with different dropout rates and learning rates\n",
    "model_base = tf.keras.Sequential(\n",
    "    [\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=3, padding=\"same\",\n",
    "                           activation=\"relu\", kernel_initializer=\"he_normal\", input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=3, padding=\"same\",\n",
    "                           activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ], name='cnn'\n",
    "    )\n",
    "\n",
    "# define the tensorboard callback\n",
    "ts = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = os.path.join(\"logs\", f\"fashion_mnist__cnn_gpu_lr{learning_rate}_do{dropout_rate}_p{patience}{ts}\")\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(logdir,\n",
    "                                                profile_batch=(100, 200))\n",
    "# define the early stopping callback\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=patience,\n",
    "                                                     restore_best_weights=True)\n",
    "# make a copy of the model so you can use it multiple times\n",
    "model = tf.keras.models.clone_model(model_base)\n",
    "\n",
    "# define the optimizer \n",
    "opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=opt,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# train the model\n",
    "history = model.fit(X_train, y_train, epochs=40,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[early_stopping_cb,tensorboard_cb])\n",
    "# you can plot history to see the training history when not using tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.get_visible_devices(\n",
    "    device_type=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  # Disable all GPUS\n",
    "  tf.config.set_visible_devices([], 'GPU')\n",
    "  visible_devices = tf.config.get_visible_devices()\n",
    "  for device in visible_devices:\n",
    "    assert device.device_type != 'GPU'\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 07:35:19.673916: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2023-04-04 07:35:19.673931: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "2023-04-04 07:35:19.676750: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2023-04-04 07:35:19.771497: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "# define the hyperparameters\n",
    "learning_rate = 0.01\n",
    "dropout_rate = 0.2\n",
    "patience = 4\n",
    "img_shape = (32, 32, 3)\n",
    "img_shape = (224, 224, 3)\n",
    "\n",
    "X_train_grey = np.expand_dims(X_train, axis=-1)\n",
    "X_train_grey = tf.image.resize(X_train_grey, [224,224])\n",
    "X_train_grey = tf.convert_to_tensor(X_train_grey)\n",
    "X_train_rgb = tf.image.grayscale_to_rgb(X_train_grey)\n",
    "\n",
    "X_valid_grey = np.expand_dims(X_valid, axis=-1)\n",
    "X_valid_grey = tf.image.resize(X_valid_grey, [224,224])\n",
    "X_valid_grey = tf.convert_to_tensor(X_valid_grey)\n",
    "X_valid_rgb = tf.image.grayscale_to_rgb(X_valid_grey)\n",
    "\n",
    "\n",
    "# define the base model for transfer learning\n",
    "base_model = tf.keras.applications.ResNet50(weights=\"imagenet\", input_shape= img_shape)\n",
    "base_model.trainable = False\n",
    "# define the model with different numbers of hidden layers and 10 output neurons and softmax activation\n",
    "# experiment with different dropout rates and learning rates\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "    base_model,\n",
    "    tf.keras.layers.BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ], name='cnn'\n",
    "    )\n",
    "\n",
    "# define the tensorboard callback\n",
    "ts = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = os.path.join(\"logs\", f\"fashion_mnist_ResNet50_lr{learning_rate}_do{dropout_rate}_p{patience}{ts}\")\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(logdir,\n",
    "                                                profile_batch=(100, 200))\n",
    "# define the early stopping callback\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=patience,\n",
    "                                                     restore_best_weights=True)\n",
    "\n",
    "# define the optimizer \n",
    "opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=opt,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# train the model\n",
    "history = model.fit(X_train_rgb, y_train, epochs=40, batch_size=2,\n",
    "                    validation_data=(X_valid_rgb, y_valid),\n",
    "                    callbacks=[early_stopping_cb,tensorboard_cb])\n",
    "# you can plot history to see the training history when not using tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39msummary()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the hyperparameters\n",
    "learning_rate = 0.01\n",
    "dropout_rate = 0.2\n",
    "patience = 4\n",
    "img_shape = (32, 32, 3)\n",
    "\n",
    "X_train_grey = np.expand_dims(X_train, axis=-1)\n",
    "X_train_grey = tf.image.resize(X_train_grey, [32,32])\n",
    "X_train_grey = tf.convert_to_tensor(X_train_grey)\n",
    "X_train_rgb = tf.image.grayscale_to_rgb(X_train_grey)\n",
    "\n",
    "X_valid_grey = np.expand_dims(X_valid, axis=-1)\n",
    "X_valid_grey = tf.image.resize(X_valid_grey, [32,32])\n",
    "X_valid_grey = tf.convert_to_tensor(X_valid_grey)\n",
    "X_valid_rgb = tf.image.grayscale_to_rgb(X_valid_grey)\n",
    "\n",
    "base_model.trainable = False\n",
    "# define the base model for transfer learning\n",
    "base_model = tf.keras.applications.efficientnet.EfficientNetB0(include_top= False, weights= \"imagenet\", input_shape= img_shape, pooling= 'max')\n",
    "\n",
    "# define the model with different numbers of hidden layers and 10 output neurons and softmax activation\n",
    "# experiment with different dropout rates and learning rates\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "    base_model,\n",
    "    tf.keras.layers.BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ], name='cnn'\n",
    "    )\n",
    "\n",
    "# define the tensorboard callback\n",
    "ts = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = os.path.join(\"logs\", f\"fashion_mnist_EfficientNetB0_lr{learning_rate}_do{dropout_rate}_p{patience}{ts}\")\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(logdir,\n",
    "                                                profile_batch=(100, 200))\n",
    "# define the early stopping callback\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=patience,\n",
    "                                                     restore_best_weights=True)\n",
    "\n",
    "# define the optimizer \n",
    "opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=opt,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# train the model\n",
    "history = model.fit(X_train_rgb, y_train, epochs=40,\n",
    "                    validation_data=(X_valid_rgb, y_valid),\n",
    "                    callbacks=[early_stopping_cb,tensorboard_cb])\n",
    "# you can plot history to see the training history when not using tensorboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hml3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac2598a53cd48ed973662853cbed9ce85601c819c2e7e5e54efa32ca245c1cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
